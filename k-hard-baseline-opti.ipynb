{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77c24eb2-118e-4191-8b8f-1424998f0b2a",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Mamiglia/challenge/blob/master/baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6457666e-51a8-486e-b250-d8e05e2005c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 78221,
     "status": "ok",
     "timestamp": 1763303254094,
     "user": {
      "displayName": "antonio cordeiro",
      "userId": "14444236176624168731"
     },
     "user_tz": -60
    },
    "id": "nsKWF-bnCZmt",
    "outputId": "7dd4d498-8c66-41d7-a53c-494a196b4bcf"
   },
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!gdown 1CVAQDuPOiwm8h9LJ8a_oOs6zOWS6EgkB\n",
    "!gdown 1ykZ9fjTxUwdiEwqagoYZiMcD5aG-7rHe\n",
    "!unzip -o -q test.zip -d data\n",
    "!unzip -o -q train.zip -d data\n",
    "\n",
    "!git clone https://github.com/Mamiglia/challenge.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96243f4-3448-499c-8e0d-fea8d98d3f7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6992,
     "status": "ok",
     "timestamp": 1763303261093,
     "user": {
      "displayName": "antonio cordeiro",
      "userId": "14444236176624168731"
     },
     "user_tz": -60
    },
    "id": "M7rYeG3vC9wx",
    "outputId": "c5cdb132-4806-475f-f094-cb6b50a029e2"
   },
   "outputs": [],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71ac95c-8f3b-4ad5-ab74-46f7dd7e6a1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8563,
     "status": "ok",
     "timestamp": 1763303269658,
     "user": {
      "displayName": "antonio cordeiro",
      "userId": "14444236176624168731"
     },
     "user_tz": -60
    },
    "id": "9c9a8587",
    "outputId": "fc9a4346-f311-4193-943e-0edca673f640"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from rich.logging import RichHandler\n",
    "from rich.progress import (BarColumn, MofNCompleteColumn, Progress, TextColumn,\n",
    "                           TimeElapsedColumn, TimeRemainingColumn)\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "# 1. Setup the logger to use RichHandler\n",
    "# This will also log to a file \"training.log\"\n",
    "logging.basicConfig(\n",
    "    level=\"INFO\",\n",
    "    format=\"%(message)s\",\n",
    "    datefmt=\"[%X]\",\n",
    "    handlers=[\n",
    "        RichHandler(rich_tracebacks=True, show_path=False, markup=True),\n",
    "        logging.FileHandler(\"training.log\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 2. Get the logger instance\n",
    "logger = logging.getLogger(\"rich\")\n",
    "logger.info(\"Logging setup complete. Logs will go to terminal and 'training.log'.\")\n",
    "\n",
    "# 3. Define a helper function to create our custom progress bar\n",
    "def get_rich_progress_bar():\n",
    "    \"\"\"Returns a Rich Progress bar instance.\"\"\"\n",
    "    return Progress(\n",
    "        TextColumn(\"[progress.description]{task.description}\"),\n",
    "        BarColumn(),\n",
    "        MofNCompleteColumn(),\n",
    "        TimeRemainingColumn(),\n",
    "        TimeElapsedColumn(),\n",
    "        # This is a custom field we will update\n",
    "        TextColumn(\"[[yellow]Loss: {task.fields[loss]:.4f}[/yellow]]\"),\n",
    "    )\n",
    "\n",
    "# Custom functions from the repo\n",
    "from challenge.src.common import generate_submission, load_data, prepare_train_data\n",
    "from challenge.src.eval import visualize_retrieval\n",
    "\n",
    "# Configuration\n",
    "EPOCHS = 3 # Max epochs for Optuna trials\n",
    "FINAL_EPOCHS = 100 # More epochs for the final model\n",
    "MODEL_PATH = \"models/mlp_best.pth\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "SCHEDULER_PATIENCE = 5\n",
    "EARLY_STOPPING_PATIENCE = 12\n",
    "DEFAULT_BATCH_SIZE = 2048\n",
    "\n",
    "# These are fixed from our dataset\n",
    "INPUT_DIM = 1024  # RoBERTa\n",
    "OUTPUT_DIM = 1536 # DINOv2\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aad4f59-232e-441b-9e3f-4b43c50c812a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49531,
     "status": "ok",
     "timestamp": 1763303319190,
     "user": {
      "displayName": "antonio cordeiro",
      "userId": "14444236176624168731"
     },
     "user_tz": -60
    },
    "id": "75dc85c5",
    "outputId": "501d4be6-6e6e-4178-d0da-00092fa1a675"
   },
   "outputs": [],
   "source": [
    "# 1. Load data\n",
    "train_data = load_data(\"data/train/train.npz\")\n",
    "\n",
    "# 2. Get unique image info *before* creating pairs\n",
    "all_image_names = train_data['images/names']\n",
    "n_images = len(all_image_names)\n",
    "label_matrix = torch.from_numpy(train_data['captions/label']).bool() # [N_captions, N_images]\n",
    "\n",
    "# 3. Create a random split of IMAGE indices\n",
    "n_train_images = int(0.9 * n_images)\n",
    "indices = torch.randperm(n_images)\n",
    "train_image_indices = indices[:n_train_images]\n",
    "val_image_indices = indices[n_train_images:]\n",
    "\n",
    "# 4. Create masks for which images are in which set\n",
    "train_image_mask = torch.zeros(n_images, dtype=torch.bool)\n",
    "train_image_mask[train_image_indices] = True\n",
    "val_image_mask = torch.zeros(n_images, dtype=torch.bool)\n",
    "val_image_mask[val_image_indices] = True\n",
    "\n",
    "# 5. Find which CAPTIONS map to which set of images\n",
    "train_caption_mask = label_matrix[:, train_image_mask].any(dim=1)\n",
    "val_caption_mask = label_matrix[:, val_image_mask].any(dim=1)\n",
    "\n",
    "# 6. Now prepare the full X, y data\n",
    "X, y, _ = prepare_train_data(train_data)\n",
    "\n",
    "# 7. Apply the LEAK-FREE masks\n",
    "X_train, X_val = X[train_caption_mask], X[val_caption_mask]\n",
    "y_train, y_val = y[train_caption_mask], y[val_caption_mask]\n",
    "\n",
    "print(f\"Total Images: {n_images}\")\n",
    "print(f\"Train Images: {n_train_images} | Val Images: {n_images - n_train_images}\")\n",
    "print(f\"Total Captions: {len(X)}\")\n",
    "print(f\"Train Captions: {len(X_train)} | Val Captions: {len(X_val)}\")\n",
    "# --- End of fix ---\n",
    "\n",
    "DEFAULT_BATCH_SIZE = 2048\n",
    "K_HARD_NEGATIVES = 64\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ec2093-10d0-4ada-a4c1-2afbfa35e99e",
   "metadata": {
    "id": "30cbff24"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim=1024, output_dim=1536,\n",
    "                 d_model=512, nhead=8, nlayers=3, dim_feedforward=2048,\n",
    "                 dropout_rate=0.3):\n",
    "        \"\"\"\n",
    "        A Transformer Encoder-based model to map embeddings, using a [CLS] token.\n",
    "\n",
    "        Args:\n",
    "            input_dim (int): Dimension of the input embedding (e.g., 1024 for RoBERTa)\n",
    "            output_dim (int): Dimension of the target embedding (e.g., 1536 for DINOv2)\n",
    "            d_model (int): The \"hidden size\" of the Transformer. Must be divisible by nhead.\n",
    "            nhead (int): The number of attention heads.\n",
    "            nlayers (int): The number of stacked Transformer Encoder layers.\n",
    "            dim_feedforward (int): The dimension of the feed-forward network in the encoder.\n",
    "            dropout_rate (float): The dropout rate to use.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # 1. Input projection: Project RoBERTa dim (1024) to the Transformer's d_model\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "\n",
    "        # 2. Learnable [CLS] token\n",
    "        # This will be prepended to the sequence.\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_model)) # (Batch, Seq, Dim)\n",
    "\n",
    "        # 3. Learnable positional embedding\n",
    "        # We now have a sequence of length 2: ([CLS], input_token)\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, 2, d_model)) # (Batch, Seq_len, Dim)\n",
    "\n",
    "        # 4. Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout_rate,\n",
    "            activation=\"gelu\",\n",
    "            batch_first=True # Ensures input shape is (Batch, Seq, Dim)\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=nlayers\n",
    "        )\n",
    "\n",
    "        # 5. Output head\n",
    "        # Takes the Transformer's output and projects it to DINOv2 dim (1536)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.output_head = nn.Linear(d_model, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (Batch, input_dim)\n",
    "\n",
    "        # 1. Project input to d_model\n",
    "        x = self.input_proj(x)\n",
    "        # x shape: (Batch, d_model)\n",
    "\n",
    "        # 2. Add \"sequence\" dimension -> (Batch, 1, d_model)\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        # 3. Prepare [CLS] token\n",
    "        # Get batch size from x\n",
    "        batch_size = x.size(0)\n",
    "        # Expand [CLS] token to match batch size -> (Batch, 1, d_model)\n",
    "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n",
    "\n",
    "        # 4. Prepend [CLS] token to the input sequence\n",
    "        # x shape: (Batch, 2, d_model)\n",
    "        x = torch.cat([cls_tokens, x], dim=1)\n",
    "\n",
    "        # 5. Add positional embedding (uses broadcasting)\n",
    "        x = x + self.pos_embed\n",
    "\n",
    "        # 6. Pass through transformer\n",
    "        # x shape: (Batch, 2, d_model)\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        # 7. Get the output of the [CLS] token (the first token)\n",
    "        # x shape: (Batch, d_model)\n",
    "        x = x[:, 0, :]\n",
    "\n",
    "        # 8. Normalize and project to final output dimension\n",
    "        x = self.norm(x)\n",
    "        x = self.output_head(x)\n",
    "        # x shape: (Batch, output_dim)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aa7699-f102-48f1-bb47-bfc05dbe18b3",
   "metadata": {
    "id": "6b2658cb"
   },
   "outputs": [],
   "source": [
    "# Modified loss function (calculates loss from a given similarity matrix)\n",
    "def k_hard_loss_from_sim(sim_matrix, temp, k, device):\n",
    "    \"\"\"Calculates InfoNCE with K-Hard Negatives from a similarity matrix.\"\"\"\n",
    "\n",
    "    # sim_matrix is assumed to be (pred_embs @ true_embs.T) * temp\n",
    "    b = sim_matrix.size(0)\n",
    "\n",
    "    # 1. Get positive similarities (the diagonal)\n",
    "    pos_sim = sim_matrix.diag().clone().unsqueeze(1) # Shape: (B, 1)\n",
    "\n",
    "    # 2. Get negative similarities\n",
    "    neg_sim_matrix = sim_matrix.clone()\n",
    "    neg_sim_matrix.fill_diagonal_(float('-inf'))\n",
    "\n",
    "    # 3. Find the K hardest negatives\n",
    "    safe_k = min(k, b - 2)\n",
    "    if safe_k <= 0:\n",
    "        labels = torch.arange(b).to(device)\n",
    "        return F.cross_entropy(sim_matrix, labels)\n",
    "\n",
    "    hard_k_neg_sims, _ = torch.topk(neg_sim_matrix, k=safe_k, dim=1) # Shape: (B, K)\n",
    "\n",
    "    # 4. Create new logits and labels\n",
    "    logits = torch.cat([pos_sim, hard_k_neg_sims], dim=1) # Shape: (B, K+1)\n",
    "    labels = torch.zeros(logits.size(0), dtype=torch.long).to(device)\n",
    "\n",
    "    # 5. Calculate loss\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    return loss\n",
    "\n",
    "# New symmetric loss function\n",
    "def symmetric_k_hard_loss(predicted_embs, true_image_embs, temp, k, device):\n",
    "    \"\"\"\n",
    "    Calculates the SYMMETRIC InfoNCE loss with K-Hard Negative Mining.\n",
    "    This version is optimized to compute the similarity matrix only once.\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalize embeddings\n",
    "    pred_embs = F.normalize(predicted_embs, p=2, dim=1)\n",
    "    true_embs = F.normalize(true_image_embs, p=2, dim=1)\n",
    "\n",
    "    # Calculate all-pairs similarity matrix ONCE\n",
    "    sim_matrix_t2i = (pred_embs @ true_embs.T) * temp\n",
    "\n",
    "    # 1. Caption-to-Image Loss (t2i)\n",
    "    loss_t2i = k_hard_loss_from_sim(sim_matrix_t2i, temp, k, device)\n",
    "\n",
    "    # 2. Image-to-Caption Loss (i2t)\n",
    "    # Just transpose the matrix! No new multiplication.\n",
    "    sim_matrix_i2t = sim_matrix_t2i.T\n",
    "    loss_i2t = k_hard_loss_from_sim(sim_matrix_i2t, temp, k, device)\n",
    "\n",
    "    # 3. Total Loss\n",
    "    loss = (loss_t2i + loss_i2t) / 2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0713da93-7142-4a9e-bc7f-57ba4527bf8a",
   "metadata": {
    "id": "0f075f66"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "# Assuming the following are defined globally (as in your notebook):\n",
    "# EPOCHS, DEVICE, INPUT_DIM, OUTPUT_DIM,\n",
    "# TransformerModel, symmetric_k_hard_loss\n",
    "\n",
    "def run_training_trial(trial, params, train_dataset, val_dataset):\n",
    "    \"\"\"\n",
    "    Train a model for one Optuna trial.\n",
    "    Accepts a dict of parameters AND the trial object.\n",
    "    Returns the best validation MRR.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create DataLoaders with the suggested batch size\n",
    "    batch_size = params[\"batch_size\"]\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # --- NEW: Define scheduler steps ---\n",
    "    # Assumes EPOCHS is a global constant (e.g., EPOCHS = 10)\n",
    "    WARMUP_STEPS = len(train_loader) # Warmup for 1 epoch\n",
    "    TOTAL_STEPS = len(train_loader) * EPOCHS\n",
    "\n",
    "    # Define TransformerModel from params\n",
    "    model = TransformerModel(\n",
    "        input_dim=INPUT_DIM,\n",
    "        output_dim=OUTPUT_DIM,\n",
    "        d_model=params[\"d_model\"],\n",
    "        nhead=params[\"nhead\"],\n",
    "        nlayers=params[\"nlayers\"],\n",
    "        dim_feedforward=params[\"dim_feedforward\"],\n",
    "        dropout_rate=params[\"dropout_rate\"]\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # --- CHANGE: Use AdamW ---\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=params[\"lr\"],\n",
    "        weight_decay=params[\"weight_decay\"]\n",
    "    )\n",
    "\n",
    "    # --- NEW: Initialize Scheduler ---\n",
    "    scheduler = CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=TOTAL_STEPS - WARMUP_STEPS, # Steps *after* warmup\n",
    "        eta_min=1e-7                      # Minimum LR\n",
    "    )\n",
    "\n",
    "    best_val_mrr = 0.0\n",
    "\n",
    "    # Assumes EARLY_STOPPING_PATIENCE is defined in your config cell (cell 2)\n",
    "    early_stopping_patience = 12\n",
    "    patience_counter = 0\n",
    "\n",
    "    temp = params[\"temperature\"]\n",
    "    alpha = params[\"mixup_alpha\"]\n",
    "    noise_std = params[\"noise_std\"]\n",
    "    k = params[\"k_hard_negatives\"] # Use k from params\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    for epoch in range(EPOCHS): # Use global EPOCHS\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        # --- MODIFICATION: Added 'i' for step counting ---\n",
    "        for i, (X_batch, y_batch) in enumerate(train_loader): # No tqdm\n",
    "            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "\n",
    "            # --- NEW: LR Scheduler & Warmup Logic ---\n",
    "            current_step = epoch * len(train_loader) + i\n",
    "            if current_step < WARMUP_STEPS:\n",
    "                # Linear Warmup\n",
    "                lr_scale = float(current_step + 1) / float(WARMUP_STEPS)\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    # Use the *target* LR from params\n",
    "                    param_group['lr'] = params[\"lr\"] * lr_scale\n",
    "            else:\n",
    "                # Cosine Decay\n",
    "                scheduler.step()\n",
    "            # ----------------------------------------\n",
    "\n",
    "            # --- NEW: Add Gaussian Noise ---\n",
    "            if noise_std > 0:\n",
    "                X_batch = X_batch + (torch.randn_like(X_batch) * noise_std)\n",
    "            # ------------------------------\n",
    "\n",
    "            # Mixup\n",
    "            lam = np.random.beta(alpha, alpha)\n",
    "            indices = torch.randperm(X_batch.size(0)).to(DEVICE)\n",
    "            X_2, y_2 = X_batch[indices], y_batch[indices]\n",
    "            X_batch_mixed = lam * X_batch + (1.0 - lam) * X_2\n",
    "            y_batch_mixed = lam * y_batch + (1.0 - lam) * y_2\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                predicted_embs = model(X_batch_mixed)\n",
    "                true_image_embs = y_batch_mixed\n",
    "\n",
    "                # --- FIX: Use 'k' from params ---\n",
    "                loss = symmetric_k_hard_loss(\n",
    "                    predicted_embs, true_image_embs, temp, k, DEVICE\n",
    "                )\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        all_reciprocal_ranks = []\n",
    "        all_ranks = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    predicted_embs = model(X_batch)\n",
    "                    true_image_embs = y_batch\n",
    "\n",
    "                    predicted_embs = F.normalize(predicted_embs, p=2, dim=1)\n",
    "                    true_image_embs = F.normalize(true_image_embs, p=2, dim=1)\n",
    "\n",
    "                    # --- NOTE: Using 'temp' from params here ---\n",
    "                    sim_matrix = (predicted_embs @ true_image_embs.T) * temp\n",
    "                    labels = torch.arange(X_batch.size(0)).to(DEVICE)\n",
    "\n",
    "                    loss = F.cross_entropy(sim_matrix, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                correct_scores = sim_matrix.diag().unsqueeze(1) + 1e-6\n",
    "                ranks = (sim_matrix > correct_scores).sum(dim=1) + 1\n",
    "                all_ranks.append(ranks)\n",
    "                all_reciprocal_ranks.append(1.0 / ranks.float())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        all_ranks = torch.cat(all_ranks)\n",
    "        all_reciprocal_ranks = torch.cat(all_reciprocal_ranks)\n",
    "        mrr = all_reciprocal_ranks.mean().item()\n",
    "\n",
    "        trial.report(mrr, epoch)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        # --- REMOVED ---\n",
    "        # scheduler.step(mrr) # This is not needed for CosineAnnealingLR\n",
    "        # -----------------\n",
    "\n",
    "        if mrr > best_val_mrr:\n",
    "            best_val_mrr = mrr\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                break\n",
    "\n",
    "    return best_val_mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aca8df6-1fab-4865-8a66-6cdfb52624c9",
   "metadata": {
    "id": "9741e634"
   },
   "outputs": [],
   "source": [
    "def train_model_final(params, train_dataset, val_dataset, device, epochs):\n",
    "    \"\"\"\n",
    "    Trains the FINAL model using the best parameters and saves it.\n",
    "    Uses Rich for logging and progress bars.\n",
    "    \"\"\"\n",
    "    logger.info(\"Training final model with best parameters...\")\n",
    "    logger.info(f\"Params: {params}\") # Log the parameters\n",
    "\n",
    "    batch_size = params[\"batch_size\"]\n",
    "    logger.info(f\"Using final batch size: {batch_size}\")\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # --- NEW: Use the 'epochs' parameter passed to the function ---\n",
    "    WARMUP_STEPS = len(train_loader) # Warmup for 1 epoch\n",
    "    TOTAL_STEPS = len(train_loader) * epochs # Use 'epochs' variable\n",
    "\n",
    "    dim_feedforward = params[\"d_model\"] * params[\"ff_multiplier\"]\n",
    "\n",
    "    model = TransformerModel(\n",
    "        input_dim=INPUT_DIM,\n",
    "        output_dim=OUTPUT_DIM,\n",
    "        d_model=params[\"d_model\"],\n",
    "        nhead=params[\"nhead\"],\n",
    "        nlayers=params[\"nlayers\"],\n",
    "        dim_feedforward=dim_feedforward, # Use the calculated value\n",
    "        dropout_rate=params[\"dropout_rate\"]\n",
    "    ).to(device)\n",
    "\n",
    "    # --- CHANGE: Use AdamW ---\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=params[\"lr\"],\n",
    "        weight_decay=params[\"weight_decay\"]\n",
    "    )\n",
    "\n",
    "    # --- NEW: Initialize Scheduler ---\n",
    "    scheduler = CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=TOTAL_STEPS - WARMUP_STEPS, # Steps *after* warmup\n",
    "        eta_min=1e-7                      # Minimum LR\n",
    "    )\n",
    "\n",
    "    best_mrr = 0.0 # Track best MRR\n",
    "    early_stopping_patience = 12\n",
    "    patience_counter = 0\n",
    "\n",
    "    temp = params[\"temperature\"]\n",
    "    alpha = params[\"mixup_alpha\"]\n",
    "    noise_std = params[\"noise_std\"]\n",
    "\n",
    "    if noise_std > 0:\n",
    "        logger.info(f\"Applying Gaussian noise with std: {noise_std:.4f}\")\n",
    "\n",
    "    k = params[\"k_hard_negatives\"] # Use k from params\n",
    "    logger.info(f\"Using K-Hard Negatives: {k}\")\n",
    "\n",
    "    history = []\n",
    "    best_val_ranks = None\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    # --- RICH PROGRESS BAR SETUP --\n",
    "    with get_rich_progress_bar() as progress:\n",
    "        epoch_task = progress.add_task(\"[cyan]Epochs\", total=epochs, loss=0.0)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # --- TRAINING --\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            train_task = progress.add_task(\"[green]   Training\", total=len(train_loader), loss=0.0)\n",
    "\n",
    "            # --- MODIFICATION: Added 'i' for step counting ---\n",
    "            for i, (X_batch, y_batch) in enumerate(train_loader):\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "                # --- NEW: LR Scheduler & Warmup Logic ---\n",
    "                current_step = epoch * len(train_loader) + i\n",
    "                if current_step < WARMUP_STEPS:\n",
    "                    # Linear Warmup\n",
    "                    lr_scale = float(current_step + 1) / float(WARMUP_STEPS)\n",
    "                    for param_group in optimizer.param_groups:\n",
    "                        param_group['lr'] = params[\"lr\"] * lr_scale\n",
    "                else:\n",
    "                    # Cosine Decay\n",
    "                    scheduler.step()\n",
    "                # ----------------------------------------\n",
    "\n",
    "                if noise_std > 0:\n",
    "                    X_batch = X_batch + (torch.randn_like(X_batch) * noise_std)\n",
    "\n",
    "                lam = np.random.beta(alpha, alpha)\n",
    "                indices = torch.randperm(X_batch.size(0)).to(device)\n",
    "                X_2, y_2 = X_batch[indices], y_batch[indices]\n",
    "                X_batch_mixed = lam * X_batch + (1.0 - lam) * X_2\n",
    "                y_batch_mixed = lam * y_batch + (1.0 - lam) * y_2\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    predicted_embs = model(X_batch_mixed)\n",
    "                    true_image_embs = y_batch_mixed\n",
    "\n",
    "                    # --- FIX: Use 'k' from params ---\n",
    "                    loss = symmetric_k_hard_loss(\n",
    "                        predicted_embs, true_image_embs, temp, k, device\n",
    "                    )\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                progress.update(train_task, advance=1, fields={\"loss\": loss.item()})\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "            progress.remove_task(train_task)\n",
    "\n",
    "            # --- VALIDATION ---\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            all_reciprocal_ranks = []\n",
    "            all_ranks = []\n",
    "            val_task = progress.add_task(\"[blue]   Validating\", total=len(val_loader), loss=0.0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for X_batch, y_batch in val_loader:\n",
    "                    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        predicted_embs = model(X_batch)\n",
    "                        true_image_embs = y_batch\n",
    "\n",
    "                        predicted_embs = F.normalize(predicted_embs, p=2, dim=1)\n",
    "                        true_image_embs = F.normalize(true_image_embs, p=2, dim=1)\n",
    "\n",
    "                        sim_matrix = (predicted_embs @ true_image_embs.T) * temp\n",
    "                        labels = torch.arange(X_batch.size(0)).to(DEVICE)\n",
    "\n",
    "                        loss = F.cross_entropy(sim_matrix, labels)\n",
    "\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    correct_scores = sim_matrix.diag().unsqueeze(1) + 1e-6\n",
    "                    ranks = (sim_matrix > correct_scores).sum(dim=1) + 1\n",
    "                    all_ranks.append(ranks)\n",
    "                    all_reciprocal_ranks.append(1.0 / ranks.float())\n",
    "\n",
    "                    progress.update(val_task, advance=1, fields={\"loss\": loss.item()})\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            progress.remove_task(val_task)\n",
    "\n",
    "            # --- AGGREGATE AND LOG METRICS ---\n",
    "            all_ranks = torch.cat(all_ranks)\n",
    "            all_reciprocal_ranks = torch.cat(all_reciprocal_ranks)\n",
    "\n",
    "            r1 = (all_ranks <= 1).float().mean().item()\n",
    "            r5 = (all_ranks <= 5).float().mean().item()\n",
    "            r10 = (all_ranks <= 10).float().mean().item()\n",
    "            mrr = all_reciprocal_ranks.mean().item()\n",
    "\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "            logger.info(\n",
    "                f\"Epoch {epoch+1:02d}: \"\n",
    "                f\"LR=[cyan]{current_lr:.1e}[/] | \"\n",
    "                f\"Train Loss=[green]{train_loss:.6f}[/] | \"\n",
    "                f\"Val Loss=[blue]{val_loss:.6f}[/] | \"\n",
    "                f\"[bold]MRR=[magenta]{mrr:.4f}[/bold]\"\n",
    "            )\n",
    "            logger.info(\n",
    "                f\"   => Metrics: R@1={r1:.4f} | \"\n",
    "                f\"R@5={r5:.4f} | \"\n",
    "                f\"R@10={r10:.4f}\"\n",
    "            )\n",
    "\n",
    "            history.append({\n",
    "                \"epoch\": epoch + 1, \"lr\": current_lr, \"train_loss\": train_loss,\n",
    "                \"val_loss\": val_loss, \"R@1\": r1, \"R@5\": r5, \"R@10\": r10, \"MRR\": mrr\n",
    "            })\n",
    "\n",
    "            # --- REMOVED ---\n",
    "            # scheduler.step(mrr) # Not needed for CosineAnnealingLR\n",
    "            # -----------------\n",
    "\n",
    "            if mrr > best_mrr:\n",
    "                best_mrr = mrr\n",
    "                Path(MODEL_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
    "                torch.save(model.state_dict(), MODEL_PATH)\n",
    "                logger.info(f\"   [bold green]âœ“ Saved best model (MRR={mrr:.6f})[/bold green]\")\n",
    "                patience_counter = 0\n",
    "                best_val_ranks = all_ranks.cpu().numpy() # Save ranks\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                logger.warning(f\"   [yellow]! No improvement. Patience: {patience_counter}/{early_stopping_patience}[/yellow]\")\n",
    "                if patience_counter >= early_stopping_patience:\n",
    "                    logger.warning(f\"--- Early stopping triggered after {epoch + 1} epochs ---\")\n",
    "                    break\n",
    "\n",
    "            progress.update(epoch_task, advance=1, fields={\"loss\": val_loss})\n",
    "\n",
    "    logger.info(f\"Training complete. Best model saved to {MODEL_PATH}\")\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "    return model, history, best_val_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e161f0e7-16f7-4426-a630-e12c52246f6c",
   "metadata": {
    "id": "963c0644"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # --- Transformer Hyperparameters ---\n",
    "    nhead = trial.suggest_categorical('nhead', [8, 16])\n",
    "    d_model = trial.suggest_categorical('d_model', [768, 1024])\n",
    "    # ----------------------------------------------------------------\n",
    "\n",
    "    # --- Suggest a multiplier, not a dynamic value ---\n",
    "    ff_multiplier = trial.suggest_categorical('ff_multiplier', [4, 6, 8])\n",
    "    dim_feedforward = d_model * ff_multiplier\n",
    "\n",
    "    nlayers = trial.suggest_int('nlayers', 1, 6)\n",
    "\n",
    "    # --- MODIFICATION: Add k_hard_negatives ---\n",
    "    k_hard_negatives = trial.suggest_categorical('k_hard_negatives', [128, 256, 512])\n",
    "\n",
    "    params = {\n",
    "        'lr': trial.suggest_float('lr', 1e-5, 5e-4, log=True),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True),\n",
    "\n",
    "        'nhead': nhead,\n",
    "        'd_model': d_model,\n",
    "        'nlayers': nlayers,\n",
    "        'dim_feedforward': dim_feedforward,\n",
    "        'noise_std': trial.suggest_float('noise_std', 0.0, 0.025),\n",
    "\n",
    "        'dropout_rate': trial.suggest_float('dropout_rate', 0.3, 0.5),\n",
    "        'temperature': trial.suggest_float('temperature', 28.0, 33.0),\n",
    "        'mixup_alpha': trial.suggest_float('mixup_alpha', 0.4, 0.6),\n",
    "\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [8192]),\n",
    "\n",
    "        # --- MODIFICATION: Pass k_hard_negatives to params ---\n",
    "        'k_hard_negatives': k_hard_negatives\n",
    "    }\n",
    "\n",
    "    # 1. Pass the 'trial' object to the training function\n",
    "    best_val_mrr = run_training_trial(trial, params, train_dataset, val_dataset)\n",
    "\n",
    "    # 2. Return the score\n",
    "    return best_val_mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b815d274-2156-4ce1-b1e3-dae72fb6ba33",
   "metadata": {
    "id": "1ea29233"
   },
   "outputs": [],
   "source": [
    "# print(\"Starting hyperparameter search...\")\n",
    "#\n",
    "# study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=50)\n",
    "#\n",
    "# print(\"\\\\nSearch complete!\")\n",
    "# print(f\"Best validation MRR: {study.best_value:.6f}\")\n",
    "# print(\"Best parameters found:\")\n",
    "# print(study.best_params)\n",
    "#\n",
    "# best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f543d6-21f1-4be6-b369-035b3d97af5e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "6608ff0f9b3d4dcda082f7b76702cab3",
      "585f3df7c94f472188d22ec5d4008319"
     ]
    },
    "executionInfo": {
     "elapsed": 400668,
     "status": "ok",
     "timestamp": 1763303720087,
     "user": {
      "displayName": "antonio cordeiro",
      "userId": "14444236176624168731"
     },
     "user_tz": -60
    },
    "id": "1937d5c0",
    "outputId": "57e9e4ea-419a-4580-fb60-4053ac946b14"
   },
   "outputs": [],
   "source": [
    "# Use the best parameters found by the study\n",
    "# If you want to use the ones from your log, uncomment the line below\n",
    "best_params =  {'nhead': 16, 'd_model': 1024, 'ff_multiplier': 4, 'nlayers': 1, 'k_hard_negatives': 128, 'lr': 0.00022732838492419994, 'weight_decay': 0.00014271358864438602, 'noise_std': 0.004940664964662731, 'dropout_rate': 0.4561339452133471, 'temperature': 29.191567155693587, 'mixup_alpha': 0.510962116079207, 'batch_size': 8192}\n",
    "model, history, best_val_ranks = train_model_final(best_params, train_dataset, val_dataset, DEVICE, FINAL_EPOCHS)\n",
    "# Save the history for later\n",
    "history_df = pd.DataFrame(history)\n",
    "history_df.to_csv(\"training_history.csv\", index=False)\n",
    "print(\"Training history saved to training_history.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8c7da-01cd-4a89-a82a-6d533bda3c81",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 945
    },
    "executionInfo": {
     "elapsed": 784,
     "status": "ok",
     "timestamp": 1763303720879,
     "user": {
      "displayName": "antonio cordeiro",
      "userId": "14444236176624168731"
     },
     "user_tz": -60
    },
    "id": "276d7b16",
    "outputId": "2e46b4c1-8a84-41fb-fd8b-0ef273fa2817"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the history\n",
    "history_df = pd.read_csv(\"training_history.csv\")\n",
    "\n",
    "# Plot Losses and MRR\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "# Plot 1: Losses\n",
    "ax1.plot(history_df['epoch'], history_df['train_loss'], label='Train Loss')\n",
    "ax1.plot(history_df['epoch'], history_df['val_loss'], label='Val Loss')\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "ax1.set_title(\"Training & Validation Loss\")\n",
    "\n",
    "# Plot 2: MRR\n",
    "ax2.plot(history_df['epoch'], history_df['MRR'], label='Validation MRR', color='green')\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.set_ylabel(\"MRR\")\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "ax2.set_title(\"Validation MRR\")\n",
    "\n",
    "# Find the best MRR epoch\n",
    "best_mrr_epoch = history_df['MRR'].idxmax()\n",
    "ax2.axvline(x=history_df.loc[best_mrr_epoch, 'epoch'], color='red', linestyle='--', label=f\"Best MRR (Epoch {history_df.loc[best_mrr_epoch, 'epoch']})\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"training_plot.png\")\n",
    "print(\"Plot saved to training_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c7d201-e427-4411-a2ef-db589b80014a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1SF3iMIfH4LqaeG08ppd1kcU5HcpoC0W4"
    },
    "executionInfo": {
     "elapsed": 4201,
     "status": "ok",
     "timestamp": 1763303725086,
     "user": {
      "displayName": "antonio cordeiro",
      "userId": "14444236176624168731"
     },
     "user_tz": -60
    },
    "id": "d060a9e8",
    "outputId": "44a05dcc-2c46-48f3-a8b5-4c54c2447bd1"
   },
   "outputs": [],
   "source": [
    "print(\"Running evaluation...\")\n",
    "model.eval()\n",
    "\n",
    "# Get the correct validation image files and embeddings\n",
    "val_img_files = train_data['images/names'][val_image_indices]\n",
    "val_img_embd = torch.from_numpy(train_data['images/embeddings'][val_image_indices]).to(DEVICE)\n",
    "\n",
    "# Get the correct validation caption text\n",
    "val_caption_text = train_data['captions/text'][val_caption_mask]\n",
    "\n",
    "# Get the correct ground-truth mapping\n",
    "# This is tricky: we need the index of the image *within the val_img_files*\n",
    "val_label_matrix_full = train_data['captions/label'][val_caption_mask]\n",
    "val_label_matrix_subset = val_label_matrix_full[:, val_image_indices]\n",
    "# val_gt_indices[i] = index 'j' such that val_img_files[j] is the correct image for val_caption_text[i]\n",
    "val_gt_indices = np.nonzero(val_label_matrix_subset)[1]\n",
    "\n",
    "\n",
    "# Sample and visualize\n",
    "for _ in range(5):\n",
    "    idx = np.random.randint(0, len(X_val))\n",
    "\n",
    "    caption_embd = X_val[idx]\n",
    "    caption_text = val_caption_text[idx]\n",
    "    gt_index_in_val_set = val_gt_indices[idx]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Predict the image embedding from the caption\n",
    "        pred_img_emb = model(caption_embd.to(DEVICE).unsqueeze(0)).cpu()\n",
    "\n",
    "        # --- Corrected Metric: Cosine Similarity ---\n",
    "        pred_img_emb_norm = F.normalize(pred_img_emb, p=2, dim=1)\n",
    "        val_img_embd_norm = F.normalize(val_img_embd.cpu(), p=2, dim=1)\n",
    "\n",
    "        # Find the most similar images\n",
    "        similarities = pred_img_emb_norm @ val_img_embd_norm.T\n",
    "\n",
    "        # Get top 5 scores and their indices\n",
    "        top_k_scores, top_k_indices = torch.topk(similarities.squeeze(0), k=5)\n",
    "\n",
    "        # ---\n",
    "\n",
    "        print(f\"\\nCAPTION: \\\"{caption_text}\\\"\")\n",
    "        print(f\"Ground Truth Image: {val_img_files[gt_index_in_val_set]}\")\n",
    "        print(\"--- Top 5 Predictions ---\")\n",
    "        for i in range(5):\n",
    "            pred_idx = top_k_indices[i].item()\n",
    "            score = top_k_scores[i].item()\n",
    "            is_correct = \"Correct!\" if pred_idx == gt_index_in_val_set else \"\"\n",
    "            print(f\"  {i+1}. {val_img_files[pred_idx]} (Score: {score:.4f}) {is_correct}\")\n",
    "\n",
    "        # Note: The provided `visualize_retrieval` might be based on L2/MSE.\n",
    "        # This manual printout uses the correct cosine similarity metric.\n",
    "        # If you want to use `visualize_retrieval`, you'd need to adapt it.\n",
    "\n",
    "        # To use the original visualizer (if it expects L2 distance):\n",
    "        # We can pass the *predicted embedding* and let it calculate L2 distance,\n",
    "        # but the model wasn't trained for that.\n",
    "\n",
    "        visualize_retrieval(\n",
    "            pred_img_emb, # The embedding, not scores\n",
    "            gt_index_in_val_set,\n",
    "            val_img_files,\n",
    "            caption_text,\n",
    "            val_img_embd.cpu(), # The true embeddings\n",
    "            k=5\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa856e26-0611-4f29-853e-0a9e577da2c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125,
     "referenced_widgets": [
      "2949382f31b14924b7d15d6a92e0881e",
      "00be1294c9a441699072eed39447d4a2"
     ]
    },
    "executionInfo": {
     "elapsed": 3665,
     "status": "ok",
     "timestamp": 1763303728776,
     "user": {
      "displayName": "antonio cordeiro",
      "userId": "14444236176624168731"
     },
     "user_tz": -60
    },
    "id": "156b49a0",
    "outputId": "67315871-84c9-4b2d-c14b-78da9c691df1"
   },
   "outputs": [],
   "source": [
    "print(\"Generating submission file...\")\n",
    "\n",
    "test_data = load_data(\"data/test/test.clean.npz\")\n",
    "test_embds = torch.from_numpy(test_data['captions/embeddings']).float()\n",
    "\n",
    "# Put model in eval mode\n",
    "model.eval()\n",
    "\n",
    "pred_embds_list = []\n",
    "test_loader = DataLoader(test_embds, batch_size=512) # Use large batch for inference\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Use the rich progress bar\n",
    "    with get_rich_progress_bar() as progress:\n",
    "        task = progress.add_task(\"[magenta]Predicting Test Set\", total=len(test_loader), loss=0.0)\n",
    "        for batch_embds in test_loader:\n",
    "            pred_batch = model(batch_embds.to(DEVICE)).cpu()\n",
    "            pred_embds_list.append(pred_batch)\n",
    "            progress.update(task, advance=1)\n",
    "\n",
    "pred_embds = torch.cat(pred_embds_list, dim=0)\n",
    "\n",
    "submission = generate_submission(test_data['captions/ids'], pred_embds, 'submission.csv')\n",
    "print(f\"Model saved to: {MODEL_PATH}\")\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "nbformat": 4,
  "nbformat_minor": 5
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
